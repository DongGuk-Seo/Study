Tips
1. 실험은 Baseline 구축부터 시작
2. Hyper-parameter 별 결과물 관리
 - 수 많은 튜닝 결과의 관리 : 각 Hyper-parameter별 성능(accuracy,loss 등), 실험마다 나오는 모델(weight) 파일
  -> 가장 간단한 방법은 모델 파일 이름에 저장(ex. model.n_layers-10.n_epochs-100.act-leaky_relu.loss-xxx.accuracy-xx.pth) - 결국 Table로 정리 필요
 - 실험 관리를 도와주는 프레임워크 : MLFlow, WanDB(부분 유료) 등
3. Batch-size는 2의 제곱 수로 하면 연산 속도가 올라감(2의 제곱 수 + 2의 제곱 수도 가능)
4. Preproccessing 중 Scaling은 Train data set에만 적용
5. Distribution's parameter :
 - Bernoulli : ʘ = {p} (확률)
 - Gaussian : ʘ = {ų,ó} (확률과 분포)
6. RNN 에서의 접근 방법
 - Non-autoregressive(Non-generative) : Bi-directional RNN 사용 권장
  -> 현재 상태가 앞/뒤 상태를 통해 정해지는 경우
 - Autoregressive(Generative) : One-to-Many case에 해당하며 Bi-directional RNN 사용 불가
  -> 현재 상태가 과거 상태에 의존하여 정해지는 경우


Focus on
1. 실무에서는 Jupyter Notebook을 사용 X -> Python Script의 CLI 환경을 이용
 - model.py : Architecture 정의 클래스
 - trainer.py: Model 학습을 위한 코드
 - datalodader.py : 데이터 불러와 전처리 수행 및 신경망에 넣기 좋은 형태로 변환
 - train.py : 사용자로부터 Hyper-parameter를 받아, Model, Trainer 및 Loader를 선언하고 학습
 - predict.py : 사용자로부터 Model과 input을 받아 추론을 수행